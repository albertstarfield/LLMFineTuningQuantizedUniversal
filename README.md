# LLMFineTuningQuantizedUniversal
LLM Finetuning while saving memory without using Nvidia, Intel x86 Exclusive, AMD ROCm, Unsloth, BitsandBytes and convert back into gguf using pytorch

I'm Designing this for Project Zephy and to be tuneable through portable device espescially ARM or RISCv
